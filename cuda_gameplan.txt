Thank you for providing the code. I've reviewed both the sequential C++ implementation and the CUDA-accelerated version of the Monte Carlo Tree Search (MCTS) algorithm for the game of Go. Let's analyze the key components and structure to determine how we can adapt this for a flexible implementation that can work with different games, including Tic-Tac-Toe, Connect4, and eventually chess.

Key components of the current implementation:

1. Game State Representation:
   - Uses a 2D array (SIZE x SIZE) to represent the board
   - Enum for piece types (EMPTY, BLACK, WHITE)

2. MCTS Node Structure:
   - Stores the board state, children nodes, parent node, statistics (simulations, scores)

3. Core MCTS Functions:
   - Selection: findMaxUctChild
   - Expansion: expand
   - Simulation: randomPlays (sequential) / randomPlaysKernel (CUDA)
   - Backpropagation: backpropagate

4. Game Logic:
   - Move generation: couldPlaceStone
   - Game end detection: computeTerritories

5. CUDA Optimization:
   - Parallelizes the simulation step across multiple games states

To adapt this for a flexible implementation that can work with different games:

1. Create a generic Game interface:
   - Define methods for game rules, move generation, and game end detection
   - Each game (Tic-Tac-Toe, Connect4, Chess) will implement this interface

2. Modify the Node structure:
   - Replace the hard-coded board representation with a generic game state
   - Use a vector or dynamic array for variable-sized game states

3. Adapt MCTS functions:
   - Modify to work with the generic Game interface
   - Keep the core MCTS algorithm intact, but make it game-agnostic

4. CUDA Optimization:
   - Create a generic CUDA kernel that can work with different game states
   - Implement game-specific CUDA functions for each game type

Here's a high-level outline of how we can refactor the code:

1. Define a Game interface:

```cpp
class Game {
public:
    virtual std::vector<int> getValidMoves(const GameState& state) = 0;
    virtual GameState applyMove(const GameState& state, int move) = 0;
    virtual bool isGameOver(const GameState& state) = 0;
    virtual float getScore(const GameState& state, int player) = 0;
    virtual GameState getInitialState() = 0;
    virtual int getCurrentPlayer(const GameState& state) = 0;
};
```

2. Modify the Node structure:

```cpp
struct Node {
    GameState state;
    std::vector<Node*> children;
    Node* parent;
    int visits;
    float score;
    // ... other necessary fields
};
```

3. Adapt MCTS functions:

```cpp
Node* select(Node* node, Game* game);
void expand(Node* node, Game* game);
float simulate(const GameState& state, Game* game);
void backpropagate(Node* node, float score);
```

4. Create game-specific implementations:

```cpp
class TicTacToe : public Game {
    // Implement TicTacToe-specific logic
};

class Connect4 : public Game {
    // Implement Connect4-specific logic
};

class Chess : public Game {
    // Implement Chess-specific logic
};
```

5. Modify the CUDA kernel:

```cpp
__global__ void simulateGamesKernel(GameState* states, float* scores, Game* game, int num_simulations) {
    // Generic CUDA simulation logic
    // Call game-specific device functions as needed
}
```

This refactoring will allow you to use the same MCTS implementation for different games while keeping game-specific logic separate. The CUDA optimization can be applied to the simulation step for all games, with game-specific optimizations implemented as needed.

Would you like me to start implementing any specific part of this refactored structure?